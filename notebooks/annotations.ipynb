{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the annotation results\n",
    "\n",
    "### Please adjust `data_dir` to your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator IDs: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10]\n",
      "Number of images in dataset: 3911\n",
      "Scenes with 1 annotator:\t 0\n",
      "Scenes with 2 annotators:\t 70\n",
      "Scenes with 3 annotators:\t 23\n",
      "Scenes with 4 annotators:\t 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from data_analysis.core.dataset import AI4ODDataset\n",
    "from data_analysis.core.filter import NumAnnotatorFilter\n",
    "\n",
    "data_dir = \"\"\n",
    "assert os.path.isdir(data_dir), \"Your data directory is not a directory.\"\n",
    "\n",
    "filters = [NumAnnotatorFilter(2)]\n",
    "dataset = AI4ODDataset(data_dir, load_images=False, filters=filters)\n",
    "\n",
    "# get list of all annotators\n",
    "annotator_ids = []\n",
    "for img_info in dataset.img_infos:\n",
    "    ids = list(img_info.annots.keys())\n",
    "    annotator_ids += ids\n",
    "\n",
    "annotator_ids = sorted(list(set(annotator_ids)))\n",
    "print(\"Annotator IDs:\", annotator_ids)\n",
    "\n",
    "print(\"Number of images in dataset:\", len(dataset))\n",
    "\n",
    "num_annotators_per_scene = [0] * 4\n",
    "for scene in dataset.scenes:\n",
    "    num_annots = len(scene.img_infos[0].annots)\n",
    "    \n",
    "    if num_annots == 1:\n",
    "        print(scene)\n",
    "    num_annotators_per_scene[num_annots - 1] += 1\n",
    "\n",
    "print(\"Scenes with 1 annotator:\\t\", num_annotators_per_scene[0])\n",
    "print(\"Scenes with 2 annotators:\\t\", num_annotators_per_scene[1])\n",
    "print(\"Scenes with 3 annotators:\\t\", num_annotators_per_scene[2])\n",
    "print(\"Scenes with 4 annotators:\\t\", num_annotators_per_scene[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_info_df = pd.DataFrame(columns=[\"img_info\", \"num_annotators\"])\n",
    "\n",
    "for img_info in dataset.img_infos:\n",
    "    num_annotators = len(img_info.annots)\n",
    "    img_info_df.loc[len(img_info_df)] = [img_info, num_annotators]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of light reflection annotations: 25109\n",
      "Number of direct vehicle annotations: 3602\n"
     ]
    }
   ],
   "source": [
    "num_directs = 0\n",
    "num_indirects = 0\n",
    "for img_info in dataset.img_infos:\n",
    "    for annot in img_info.annots.values():\n",
    "        num_indirects += len(annot.reflections)\n",
    "        num_directs += len([v for v in annot.vehicles if v.direct])\n",
    "\n",
    "print(\"Number of light reflection annotations:\", num_indirects)\n",
    "print(\"Number of direct vehicle annotations:\", num_directs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Bounding Box Annotations\n",
    "\n",
    "### Number of bounding boxes per image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_analysis.boxes.utils import count_num_boxes\n",
    "\n",
    "img_ids = [img_info.img_name.split(\".\")[0] for img_info in dataset.img_infos]\n",
    "count_box_df_indirect = pd.DataFrame(columns=annotator_ids, index=img_ids)\n",
    "count_box_df_direct = pd.DataFrame(columns=annotator_ids, index=img_ids)\n",
    "\n",
    "for img_info in dataset.img_infos:\n",
    "    img_id = img_info.img_name.split(\".\")[0]\n",
    "    for annotator_id, annot in img_info.annots.items():\n",
    "        num_boxes_indirect = count_num_boxes(annot, indirect=True, direct=False)\n",
    "        count_box_df_indirect.loc[img_id][annotator_id] = num_boxes_indirect\n",
    "\n",
    "        num_boxes_direct = count_num_boxes(annot, indirect=False, direct=True)\n",
    "        count_box_df_direct.loc[img_id][annotator_id] = num_boxes_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference in number of bounding boxes\n",
      "Direct:\t\t 0.06\n",
      "Indirect:\t 1.51\n"
     ]
    }
   ],
   "source": [
    "diff_direct = count_box_df_direct.max(axis=\"columns\") - count_box_df_direct.min(axis=\"columns\") \n",
    "\n",
    "diff_indirect = count_box_df_indirect.max(axis=\"columns\") - count_box_df_indirect.min(axis=\"columns\")\n",
    "\n",
    "mean_diff_direct = diff_direct.mean()\n",
    "mean_diff_indirect = diff_indirect.mean()\n",
    "\n",
    "print(\"Mean difference in number of bounding boxes\")\n",
    "print(\"Direct:\\t\\t\", round(mean_diff_direct, 2))\n",
    "print(\"Indirect:\\t\", round(mean_diff_indirect, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Boxes (non-exclusive) & IoUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from data_analysis.boxes.match import get_matches\n",
    "\n",
    "direct_matches = {}\n",
    "direct_unmatches = {}\n",
    "\n",
    "indirect_matches = {}\n",
    "indirect_unmatches = {}\n",
    "\n",
    "# new columns\n",
    "img_info_df[\"direct_match_exclusive\"] = None\n",
    "img_info_df[\"direct_unmatch_exclusive\"] = None\n",
    "\n",
    "img_info_df[\"direct_match_non_exclusive\"] = None\n",
    "img_info_df[\"direct_unmatch_non_exclusive\"] = None\n",
    "\n",
    "img_info_df[\"indirect_match_exclusive\"] = None\n",
    "img_info_df[\"indirect_unmatch_exclusive\"] = None\n",
    "\n",
    "img_info_df[\"indirect_match_non_exclusive\"] = None\n",
    "img_info_df[\"indirect_unmatch_non_exclusive\"] = None\n",
    "\n",
    "\n",
    "for i, row in img_info_df.iterrows():\n",
    "    img_info = row[\"img_info\"]\n",
    "    num_annotators = row[\"num_annotators\"]\n",
    "    \n",
    "    if num_annotators > 1:\n",
    "        # non-exclusive indirect\n",
    "        matches, unmatches = get_matches(img_info, direct=False, indirect=True, iou_thresh=0.01, exclusive=False)\n",
    "        img_info_df.at[i, \"indirect_match_non_exclusive\"] = matches\n",
    "        img_info_df.at[i, \"indirect_unmatch_non_exclusive\"] = unmatches\n",
    "\n",
    "        # non-exclusive direct\n",
    "        matches, unmatches = get_matches(img_info, direct=True, indirect=False, iou_thresh=0.01, exclusive=False)\n",
    "        img_info_df.at[i, \"direct_match_non_exclusive\"] = matches\n",
    "        img_info_df.at[i, \"direct_unmatch_non_exclusive\"] = unmatches\n",
    "\n",
    "        # exclusive indirect\n",
    "        matches, unmatches = get_matches(img_info, direct=False, indirect=True, iou_thresh=0.01, exclusive=True)\n",
    "        img_info_df.at[i, \"indirect_match_exclusive\"] = matches\n",
    "        img_info_df.at[i, \"indirect_unmatch_exclusive\"] = unmatches\n",
    "\n",
    "        # exclusive direct\n",
    "        matches, unmatches = get_matches(img_info, direct=True, indirect=False, iou_thresh=0.01, exclusive=True)\n",
    "        img_info_df.at[i, \"direct_match_exclusive\"] = matches\n",
    "        img_info_df.at[i, \"direct_unmatch_exclusive\"] = unmatches\n",
    "\n",
    "        matches, unmatches = get_matches(img_info, direct=True, indirect=False, iou_thresh=0.01, exclusive=False)\n",
    "        direct_matches[img_info.img_name] = matches\n",
    "        direct_unmatches[img_info.img_name] = unmatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU for matching reflection annotations: 0.41\n",
      "Mean IoU for matching vehicle annotations: 0.6\n",
      "\n",
      "Mean number of matching reflection annotations per image: 2.8\n",
      "Mean number of matching vehicle annotations per image: 1.01\n",
      "\n",
      "Mean number of unmatching reflection annotations per image: 2.11\n",
      "Mean number of unmatching vehicle annotations per image: 0.19\n"
     ]
    }
   ],
   "source": [
    "\n",
    "indirect_ious = []\n",
    "direct_ious = []\n",
    "\n",
    "# indirect_unmatches_per_img = []\n",
    "# indirect_matches_per_img = []\n",
    "\n",
    "num_exclusive_indirect = []\n",
    "num_exclusive_direct = []\n",
    "\n",
    "num_matches_non_exclusive_direct = []\n",
    "num_matches_non_exclusive_indirect = []\n",
    "\n",
    "num_unmatches_non_exclusive_direct = []\n",
    "num_unmatches_non_exclusive_indirect = []\n",
    "\n",
    "indirect_match_overlapping = []\n",
    "direct_match_overlapping = []\n",
    "\n",
    "for i, row in img_info_df.iterrows():\n",
    "    if row[\"indirect_match_non_exclusive\"] or row[\"indirect_unmatch_non_exclusive\"]:\n",
    "        indirect_ious += [item[1] for item in row[\"indirect_match_non_exclusive\"]]\n",
    "        num_matches_non_exclusive_indirect.append(len(row[\"indirect_match_non_exclusive\"]))\n",
    "        num_unmatches_non_exclusive_indirect.append(len(row[\"indirect_unmatch_non_exclusive\"]))\n",
    "        \n",
    "    if row[\"indirect_match_exclusive\"]:\n",
    "        num_exclusive_direct.append(len(row[\"indirect_match_exclusive\"]))\n",
    "    \n",
    "    if row[\"direct_match_non_exclusive\"] or row[\"direct_unmatch_non_exclusive\"]:\n",
    "        direct_ious += [item[1] for item in row[\"direct_match_non_exclusive\"]]\n",
    "        num_matches_non_exclusive_direct.append(len(row[\"direct_match_non_exclusive\"]))\n",
    "        num_unmatches_non_exclusive_direct.append(len(row[\"direct_unmatch_non_exclusive\"]))\n",
    "        \n",
    "    if row[\"direct_match_exclusive\"]:\n",
    "        num_exclusive_direct.append(len(row[\"direct_match_exclusive\"]))\n",
    "    \n",
    "    if row[\"indirect_match_non_exclusive\"] or row[\"indirect_match_exclusive\"]:\n",
    "        exclusive = row[\"indirect_match_exclusive\"]\n",
    "        exclusive = exclusive if exclusive else []\n",
    "        \n",
    "        non_exclusive = row[\"indirect_match_non_exclusive\"]\n",
    "        non_exclusive = non_exclusive if non_exclusive else []\n",
    "        \n",
    "        indirect_match_overlapping.append(len(non_exclusive) - len(exclusive))\n",
    "    \n",
    "    if row[\"direct_match_exclusive\"] or row[\"direct_match_non_exclusive\"]:\n",
    "        exclusive = row[\"direct_match_exclusive\"]\n",
    "        exclusive = exclusive if exclusive else []\n",
    "\n",
    "        non_exclusive = row[\"direct_match_non_exclusive\"]\n",
    "        non_exclusive = non_exclusive if non_exclusive else []\n",
    "\n",
    "        direct_match_overlapping.append(len(non_exclusive) - len(exclusive))\n",
    "\n",
    "print(\"Mean IoU for matching reflection annotations:\", round(statistics.mean(indirect_ious), 2))\n",
    "print(\"Mean IoU for matching vehicle annotations:\", round(statistics.mean(direct_ious), 2))\n",
    "print()\n",
    "print(\"Mean number of matching reflection annotations per image:\", round(statistics.mean(num_matches_non_exclusive_indirect), 2))\n",
    "print(\"Mean number of matching vehicle annotations per image:\", round(statistics.mean(num_matches_non_exclusive_direct), 2))\n",
    "print()\n",
    "print(\"Mean number of unmatching reflection annotations per image:\", round(statistics.mean(num_unmatches_non_exclusive_indirect), 2))\n",
    "print(\"Mean number of unmatching vehicle annotations per image:\", round(statistics.mean(num_unmatches_non_exclusive_direct), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reflection matches (non-exclusive): 1557\n",
      "Total number of reflection UNmatches annotations (non-exclusive): 288\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of reflection matches (non-exclusive):\", sum(num_matches_non_exclusive_direct))\n",
    "print(\"Total number of reflection UNmatches annotations (non-exclusive):\", sum(num_unmatches_non_exclusive_direct))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of matches exclusive vs. non-exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of OVERLAPPING reflections among annotators: 0.64\n",
      "Mean number of OVERLAPPING vehicles among annotators: 0.02\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Mean number of OVERLAPPING reflections among annotators:\", round(statistics.mean(indirect_match_overlapping), 2))\n",
    "\n",
    "print(\"Mean number of OVERLAPPING vehicles among annotators:\", round(statistics.mean(direct_match_overlapping), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_analysis.core.meta import ReflectionType\n",
    "\n",
    "img_info_df[\"reflection_type\"] = None\n",
    "for i, row in img_info_df.iterrows():\n",
    "    if row[\"indirect_match_non_exclusive\"]:\n",
    "        row_types = []\n",
    "        for combi, box_iou in row[\"indirect_match_non_exclusive\"]:\n",
    "            types = [inst.type for inst in combi]\n",
    "            unique_types = set(types)\n",
    "            if len(unique_types) != 1:\n",
    "                t = \"ambiguous\"\n",
    "            else:\n",
    "                t = types[0]\n",
    "            row_types.append(t)\n",
    "        img_info_df.at[i, \"reflection_type\"] = row_types\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection types for matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 9407\n",
      "ReflectionType.FLOOR 17.3\n",
      "ReflectionType.CAR 65.04\n",
      "ReflectionType.CURB 4.07\n",
      "ReflectionType.OTHER 5.35\n",
      "ambiguous 8.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_reflection_types = {k: 0 for k in ReflectionType}\n",
    "num_reflection_types[\"ambiguous\"] = 0\n",
    "\n",
    "for i, row in img_info_df.iterrows():\n",
    "    if row[\"reflection_type\"]:\n",
    "        for t in row[\"reflection_type\"]:\n",
    "            num_reflection_types[t] += 1\n",
    "\n",
    "total = 0\n",
    "for k, v in num_reflection_types.items():\n",
    "    total += v\n",
    "\n",
    "print()\n",
    "print(\"Total:\", total)\n",
    "\n",
    "for k, v in num_reflection_types.items():\n",
    "    if v > 0:\n",
    "        print(k, round(100 * v / total, 2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection types for **all** annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 25109\n",
      "ReflectionType.FLOOR 16.12\n",
      "ReflectionType.CAR 69.96\n",
      "ReflectionType.CURB 5.08\n",
      "ReflectionType.OTHER 8.84\n"
     ]
    }
   ],
   "source": [
    "num_reflection_types = {k: 0 for k in ReflectionType}\n",
    "total = 0\n",
    "\n",
    "for img_info in dataset.img_infos:\n",
    "    for annot in img_info.annots.values():\n",
    "        for reflection in annot.reflections:\n",
    "            num_reflection_types[reflection.type] += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Total:\", total)\n",
    "for k, v in num_reflection_types.items():\n",
    "    if v > 0:\n",
    "        print(k, round(100 * v / total, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73147aea8bfdc66a241f576da43aedea6fcb31782a9fa2ea88d4293d9bb3ba46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
